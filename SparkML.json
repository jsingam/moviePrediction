{"paragraphs":[{"text":"import java.io.File\nimport scala.io.Source\n\nimport org.apache.log4j.Logger\nimport org.apache.log4j.Level\n\nimport org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.rdd._\nimport org.apache.spark.mllib.recommendation.{ALS, Rating, MatrixFactorizationModel}","user":"anonymous","dateUpdated":"2020-03-01T18:12:18+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import java.io.File\nimport scala.io.Source\nimport org.apache.log4j.Logger\nimport org.apache.log4j.Level\nimport org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.rdd._\nimport org.apache.spark.mllib.recommendation.{ALS, Rating, MatrixFactorizationModel}\n"}]},"apps":[],"jobName":"paragraph_1583083144904_686519991","id":"20200301-171904_864372412","dateCreated":"2020-03-01T17:19:04+0000","dateStarted":"2020-03-01T18:12:18+0000","dateFinished":"2020-03-01T18:12:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:172"},{"text":"val movieLensHomeDir = \"s3://asbv/\"\n\nval movies = sc.textFile(movieLensHomeDir + \"movies.dat\").map { line =>\n  val fields = line.split(\"::\")\n  // format: (movieId, movieName)\n  (fields(0).toInt, fields(1))\n}.collect.toMap\n\nval ratings = sc.textFile(movieLensHomeDir + \"ratings.dat\").map { line =>\n  val fields = line.split(\"::\")\n  // format: (timestamp % 10, Rating(userId, movieId, rating))\n  (fields(3).toLong % 10, Rating(fields(0).toInt, fields(1).toInt, fields(2).toDouble))\n}","user":"anonymous","dateUpdated":"2020-03-01T18:12:18+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"movieLensHomeDir: String = s3://asbv/\nmovies: scala.collection.immutable.Map[Int,String] = Map(2163 -> Attack of the Killer Tomatoes! (1980), 8607 -> Tokyo Godfathers (2003), 645 -> Nelly & Monsieur Arnaud (1995), 42900 -> Cul-de-sac (1966), 892 -> Twelfth Night (1996), 69 -> Friday (1995), 53550 -> Rescue Dawn (2006), 37830 -> Final Fantasy VII: Advent Children (2004), 5385 -> Last Waltz, The (1978), 5810 -> 8 Mile (2002), 7375 -> Prince & Me, The (2004), 5659 -> Rocking Horse Winner, The (1950), 2199 -> Phoenix (1998), 8062 -> Dahmer (2002), 3021 -> Funhouse, The (1981), 8536 -> Intended, The (2002), 5437 -> Manhattan Project, The (1986), 1322 -> Amityville 1992: It's About Time (1992), 1665 -> Bean (1997), 5509 -> Biggie and Tupac (2002), 5686 -> Russian Ark (Russkiy Kovcheg) (2002),..."}]},"apps":[],"jobName":"paragraph_1583083158963_543671409","id":"20200301-171918_2139536661","dateCreated":"2020-03-01T17:19:18+0000","dateStarted":"2020-03-01T18:12:18+0000","dateFinished":"2020-03-01T18:12:19+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:173"},{"text":"val numRatings = ratings.count\nval numUsers = ratings.map(_._2.user).distinct.count\nval numMovies = ratings.map(_._2.product).distinct.count\n\nprintln(\"Got \" + numRatings + \" ratings from \"\n  + numUsers + \" users on \" + numMovies + \" movies.\")","user":"anonymous","dateUpdated":"2020-03-01T18:12:19+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Got 10000054 ratings from 69878 users on 10677 movies.\nnumRatings: Long = 10000054\nnumUsers: Long = 69878\nnumMovies: Long = 10677\n"}]},"apps":[],"jobName":"paragraph_1583084939359_-485222136","id":"20200301-174859_1589190656","dateCreated":"2020-03-01T17:48:59+0000","dateStarted":"2020-03-01T18:12:19+0000","dateFinished":"2020-03-01T18:12:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:174"},{"text":"val training = ratings.filter(x => x._1 < 6)\n  .values\n  .cache()\nval validation = ratings.filter(x => x._1 >= 6 && x._1 < 8)\n  .values\n  .cache()\nval test = ratings.filter(x => x._1 >= 8).values.cache()\n\nval numTraining = training.count()\nval numValidation = validation.count()\nval numTest = test.count()\n\nprintln(\"Training: \" + numTraining + \", validation: \" + numValidation + \", test: \" + numTest)","user":"anonymous","dateUpdated":"2020-03-01T18:12:43+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Training: 6002473, validation: 1999675, test: 1997906\ntraining: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[2625] at values at <console>:59\nvalidation: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[2627] at values at <console>:62\ntest: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[2629] at values at <console>:64\nnumTraining: Long = 6002473\nnumValidation: Long = 1999675\nnumTest: Long = 1997906\n"}]},"apps":[],"jobName":"paragraph_1583085007309_-1289331882","id":"20200301-175007_59165217","dateCreated":"2020-03-01T17:50:07+0000","dateStarted":"2020-03-01T18:12:43+0000","dateFinished":"2020-03-01T18:13:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:175"},{"text":"/** Compute RMSE (Root Mean Squared Error). */\ndef computeRmse(model: MatrixFactorizationModel, data: RDD[Rating], n: Long): Double = {\n    val predictions: RDD[Rating] = model.predict(data.map(x => (x.user, x.product)))\n    val predictionsAndRatings = predictions.map(x => ((x.user, x.product), x.rating))\n    .join(data.map(x => ((x.user, x.product), x.rating))).values\n    math.sqrt(predictionsAndRatings.map(x => (x._1 - x._2) * (x._1 - x._2)).reduce(_ + _) / n)\n}","user":"anonymous","dateUpdated":"2020-03-01T18:13:11+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"computeRmse: (model: org.apache.spark.mllib.recommendation.MatrixFactorizationModel, data: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating], n: Long)Double\n"}]},"apps":[],"jobName":"paragraph_1583085084259_-1682561145","id":"20200301-175124_1333988884","dateCreated":"2020-03-01T17:51:24+0000","dateStarted":"2020-03-01T18:13:11+0000","dateFinished":"2020-03-01T18:13:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:176"},{"text":"val ranks = List(8, 12)\nval lambdas = List(0.1, 10.0)\nval numIters = List(10, 20)\nvar bestModel: Option[MatrixFactorizationModel] = None\nvar bestValidationRmse = Double.MaxValue\nvar bestRank = 0\nvar bestLambda = -1.0\nvar bestNumIter = -1\nfor (rank <- ranks; lambda <- lambdas; numIter <- numIters) {\n  val model = ALS.train(training, rank, numIter, lambda)\n  val validationRmse = computeRmse(model, validation, numValidation)\n  println(\"RMSE (validation) = \" + validationRmse + \" for the model trained with rank = \" \n    + rank + \", lambda = \" + lambda + \", and numIter = \" + numIter + \".\")\n  if (validationRmse < bestValidationRmse) {\n    bestModel = Some(model)\n    bestValidationRmse = validationRmse\n    bestRank = rank\n    bestLambda = lambda\n    bestNumIter = numIter\n  }\n}","user":"anonymous","dateUpdated":"2020-03-01T18:13:11+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"RMSE (validation) = 0.8214876914068981 for the model trained with rank = 8, lambda = 0.1, and numIter = 10.\nRMSE (validation) = 0.8190929388894747 for the model trained with rank = 8, lambda = 0.1, and numIter = 20.\nRMSE (validation) = 3.667982949261605 for the model trained with rank = 8, lambda = 10.0, and numIter = 10.\nRMSE (validation) = 3.667982949261605 for the model trained with rank = 8, lambda = 10.0, and numIter = 20.\nRMSE (validation) = 0.8191357578135382 for the model trained with rank = 12, lambda = 0.1, and numIter = 10.\nRMSE (validation) = 0.8158658154518492 for the model trained with rank = 12, lambda = 0.1, and numIter = 20.\nRMSE (validation) = 3.667982949261605 for the model trained with rank = 12, lambda = 10.0, and numIter = 10.\nRMSE (validation) = 3.667982949261605 for the model trained with rank = 12, lambda = 10.0, and numIter = 20.\nranks: List[Int] = List(8, 12)\nlambdas: List[Double] = List(0.1, 10.0)\nnumIters: List[Int] = List(10, 20)\nbestModel: Option[org.apache.spark.mllib.recommendation.MatrixFactorizationModel] = Some(org.apache.spark.mllib.recommendation.MatrixFactorizationModel@310ee15e)\nbestValidationRmse: Double = 0.8158658154518492\nbestRank: Int = 12\nbestLambda: Double = 0.1\nbestNumIter: Int = 20\n"}]},"apps":[],"jobName":"paragraph_1583085156980_27276759","id":"20200301-175236_1109028753","dateCreated":"2020-03-01T17:52:36+0000","dateStarted":"2020-03-01T18:13:11+0000","dateFinished":"2020-03-01T18:21:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:177"},{"text":"// evaluate the best model on the test set\nval testRmse = computeRmse(bestModel.get, test, numTest)\n\nprintln(\"The best model was trained with rank = \" + bestRank + \" and lambda = \" + bestLambda\n  + \", and numIter = \" + bestNumIter + \", and its RMSE on the test set is\"\n  + testRmse + \".\")","user":"anonymous","dateUpdated":"2020-03-01T18:21:07+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"The best model was trained with rank = 12 and lambda = 0.1, and numIter = 20, and its RMSE on the test set is0.8159568343608667.\ntestRmse: Double = 0.8159568343608667\n"}]},"apps":[],"jobName":"paragraph_1583085183469_361167258","id":"20200301-175303_2043029332","dateCreated":"2020-03-01T17:53:03+0000","dateStarted":"2020-03-01T18:21:07+0000","dateFinished":"2020-03-01T18:21:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:178"},{"text":"// create a naive baseline and compare it with the best model\nval meanRating = training.union(validation).map(_.rating).mean\nval baselineRmse = \n  math.sqrt(test.map(x => (meanRating - x.rating) * (meanRating - x.rating)).mean)\nval improvement = (baselineRmse - testRmse) / baselineRmse * 100\nprintln(\"The best model improves the baseline by \" + \"%1.2f\".format(improvement) + \"%.\")","user":"anonymous","dateUpdated":"2020-03-01T18:21:16+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"The best model improves the baseline by 23.01%.\nmeanRating: Double = 3.512362305720862\nbaselineRmse: Double = 1.0597828264660583\nimprovement: Double = 23.00716580945658\n"}]},"apps":[],"jobName":"paragraph_1583085732190_74869580","id":"20200301-180212_1171960666","dateCreated":"2020-03-01T18:02:12+0000","dateStarted":"2020-03-01T18:21:16+0000","dateFinished":"2020-03-01T18:21:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:179"},{"text":"val candidates = sc.parallelize(movies.keys.toSeq)\nval recommendations = bestModel.get\n  .predict(candidates.map((100, _)))\n  .collect()\n  .sortBy(- _.rating)\n  .take(10)\n\nvar i = 1\nprintln(\"Movies recommended for you:\")\nrecommendations.foreach { r =>\n  println(\"%2d\".format(i) + \": \" + movies(r.product))\n  i += 1\n}","user":"anonymous","dateUpdated":"2020-03-01T18:21:16+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Movies recommended for you:\n 1: Eve and the Fire Horse (2005)\n 2: Maradona by Kusturica (2008)\n 3: Low Life, The (1995)\n 4: Power of Nightmares: The Rise of the Politics of Fear, The (2004)\n 5: Shadows of Forgotten Ancestors (1964)\n 6: Pulp Fiction (1994)\n 7: Gonzo: The Life and Work of Dr. Hunter S. Thompson (2008)\n 8: Hospital (1970)\n 9: Godfather, The (1972)\n10: Unreasonable Man, An (2006)\ncandidates: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[5164] at parallelize at <console>:59\nrecommendations: Array[org.apache.spark.mllib.recommendation.Rating] = Array(Rating(100,60983,4.338544778224347), Rating(100,61742,3.8668278848638296), Rating(100,32090,3.8227297602003074), Rating(100,53883,3.7584945181061187), Rating(100,42783,3.7437096216391037), Rating(100,296,3.56650247403583), Rating(100,60291,3.533180130041427), Rating(100,64280,3.5136938646254547), Rating(100,858,3.5121377484362695), Rating(100,55156,3.503497983664526))\ni: Int = 11\n"}]},"apps":[],"jobName":"paragraph_1583085856009_1782801502","id":"20200301-180416_1067012941","dateCreated":"2020-03-01T18:04:16+0000","dateStarted":"2020-03-01T18:21:16+0000","dateFinished":"2020-03-01T18:21:17+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:180"},{"text":"val candidates = sc.parallelize(movies.keys.toSeq)\nval recommendations = bestModel.get\n  .predict(candidates.map((100, _)))\n  .collect()\n  .sortBy(- _.rating)\n  .take(10)\n\nvar i = 1\nprintln(\"Movies recommended for you:\")\nrecommendations.foreach { r =>\n  println(\"%2d\".format(i) + \": \" + movies(r.product))\n  i += 1\n}","user":"anonymous","dateUpdated":"2020-03-01T18:21:17+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Movies recommended for you:\n 1: Eve and the Fire Horse (2005)\n 2: Maradona by Kusturica (2008)\n 3: Low Life, The (1995)\n 4: Power of Nightmares: The Rise of the Politics of Fear, The (2004)\n 5: Shadows of Forgotten Ancestors (1964)\n 6: Pulp Fiction (1994)\n 7: Gonzo: The Life and Work of Dr. Hunter S. Thompson (2008)\n 8: Hospital (1970)\n 9: Godfather, The (1972)\n10: Unreasonable Man, An (2006)\ncandidates: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[5174] at parallelize at <console>:59\nrecommendations: Array[org.apache.spark.mllib.recommendation.Rating] = Array(Rating(100,60983,4.338544778224347), Rating(100,61742,3.8668278848638296), Rating(100,32090,3.8227297602003074), Rating(100,53883,3.7584945181061187), Rating(100,42783,3.7437096216391037), Rating(100,296,3.56650247403583), Rating(100,60291,3.533180130041427), Rating(100,64280,3.5136938646254547), Rating(100,858,3.5121377484362695), Rating(100,55156,3.503497983664526))\ni: Int = 11\n"}]},"apps":[],"jobName":"paragraph_1583085886909_-808725236","id":"20200301-180446_2086886658","dateCreated":"2020-03-01T18:04:46+0000","dateStarted":"2020-03-01T18:21:17+0000","dateFinished":"2020-03-01T18:21:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:181"},{"text":"val moviesWithGenres = sc.textFile(movieLensHomeDir + \"movies.dat\").map { line =>\n  val fields = line.split(\"::\")\n  // format: (movieId, movieName, genre information)\n  (fields(0).toInt, fields(2))\n}.collect.toMap","user":"anonymous","dateUpdated":"2020-03-01T18:21:18+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"moviesWithGenres: scala.collection.immutable.Map[Int,String] = Map(2163 -> Comedy|Horror, 8607 -> Adventure|Animation|Drama, 645 -> Drama, 42900 -> Comedy|Crime|Drama|Thriller, 892 -> Comedy|Drama|Romance, 69 -> Comedy, 53550 -> Action|Adventure|Drama|War, 37830 -> Action|Adventure|Animation|Fantasy|Sci-Fi, 5385 -> Documentary, 5810 -> Drama, 7375 -> Comedy|Romance, 5659 -> Drama|Horror, 2199 -> Crime|Drama, 8062 -> Drama|Horror|Thriller, 3021 -> Horror, 8536 -> Drama|Thriller, 5437 -> Comedy|Thriller, 1322 -> Horror, 1665 -> Comedy, 5509 -> Documentary, 5686 -> Drama|Fantasy|War, 1036 -> Action|Crime|Thriller, 2822 -> Adventure|Romance, 7304 -> Animation|Comedy|Fantasy|Musical, 54999 -> Action|Adventure|Thriller, 2630 -> Drama, 6085 -> Comedy|Drama, 3873 -> Comedy|Western, 4188 -> Chil..."}]},"apps":[],"jobName":"paragraph_1583085917649_302203831","id":"20200301-180517_556572292","dateCreated":"2020-03-01T18:05:17+0000","dateStarted":"2020-03-01T18:21:18+0000","dateFinished":"2020-03-01T18:21:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:182"},{"text":"val comedyMovies = moviesWithGenres.filter(_._2.matches(\".*Comedy.*\")).keys\nval candidates = sc.parallelize(comedyMovies.toSeq)\nval recommendations = bestModel.get\n  .predict(candidates.map((100, _)))\n  .collect()\n  .sortBy(- _.rating)\n  .take(5)\n\nvar i = 1\nprintln(\"Comedy Movies recommended for you:\")\nrecommendations.foreach { r =>\n  println(\"%2d\".format(i) + \": \" + movies(r.product))\n  i += 1\n}","user":"anonymous","dateUpdated":"2020-03-01T18:21:18+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Comedy Movies recommended for you:\n 1: Pulp Fiction (1994)\n 2: Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)\n 3: Yojimbo (1961)\n 4: Mafioso (1962)\n 5: One Flew Over the Cuckoo's Nest (1975)\ncomedyMovies: Iterable[Int] = Set(2163, 42900, 892, 69, 7375, 5437, 1665, 7304, 6085, 3873, 26413, 4201, 4447, 33004, 3962, 5422, 5469, 3944, 6387, 3883, 62851, 5116, 4094, 6167, 5088, 2889, 59858, 2295, 2306, 4571, 5857, 4464, 101, 2109, 1454, 4909, 2031, 5896, 59625, 2072, 8663, 4062, 3399, 54256, 33675, 6544, 4169, 4899, 53578, 6712, 55020, 5950, 3167, 31160, 4183, 909, 4290, 3477, 333, 3979, 2463, 3397, 49110, 3581, 8784, 3830, 6317, 518, 7990, 2499, 8843, 1083, 468, 54193, 5205, 6172, 4015, 26842, 234, 6690, 2331, 3566, 4728, 6954, 4877, 6014, 5582, 4992, 5131, 6374, 88, 50354, 47047, 32289, 352, 53993, 33145, 1855, 45722, 5454, 56176, 1211, 3990, 7888, 4714, 1158, 582, 762, 3072, 8883, 1005, 5141, 115, 6944, 3317, 5168, 4500, 65027, 7409, 5718, 34018, 37384, 46976, 276, 2622, 4402..."}]},"apps":[],"jobName":"paragraph_1583085935799_-1379743419","id":"20200301-180535_657009850","dateCreated":"2020-03-01T18:05:35+0000","dateStarted":"2020-03-01T18:21:18+0000","dateFinished":"2020-03-01T18:21:19+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:183"},{"text":"bestModel.get.save(sc, \"s3://asbv/model/recommendation\")\nval sameModel = MatrixFactorizationModel.load(sc,  \"s3://asbv/model/recommendation\")","user":"anonymous","dateUpdated":"2020-03-01T18:21:19+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory s3://asbv/model/recommendation/metadata already exists\n  at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)\n  at org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:289)\n  at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1096)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1094)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1067)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1032)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:958)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:957)\n  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1499)\n  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)\n  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1478)\n  at org.apache.spark.mllib.recommendation.MatrixFactorizationModel$SaveLoadV1_0$.save(MatrixFactorizationModel.scala:378)\n  at org.apache.spark.mllib.recommendation.MatrixFactorizationModel.save(MatrixFactorizationModel.scala:216)\n  ... 55 elided\n"}]},"apps":[],"jobName":"paragraph_1583085999469_115947630","id":"20200301-180639_1753363863","dateCreated":"2020-03-01T18:06:39+0000","dateStarted":"2020-03-01T18:21:19+0000","dateFinished":"2020-03-01T18:21:19+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:184"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1583086049069_826295444","id":"20200301-180729_200711448","dateCreated":"2020-03-01T18:07:29+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:185"}],"name":"SparkML","id":"2F44VM72P","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}